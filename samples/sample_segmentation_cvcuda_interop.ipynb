{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample illustrates torch segmentation. \\\n",
    "To illustrate interop with cvcuda and nvimgcodec, they are used to:\n",
    "- OSD operations like bbox and label drawing.\n",
    "- JPEG compression.\n",
    "\n",
    "For memory sharing both DLPack and CAI (CUDA Array Interface) are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from Python 3.8 DLL search policy has changed.\n",
    "# We need to add path to CUDA DLLs explicitly.\n",
    "import os\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    # Add CUDA_PATH env variable\n",
    "    cuda_path = os.environ[\"CUDA_PATH\"]\n",
    "    if cuda_path:\n",
    "        os.add_dll_directory(os.path.join(cuda_path, \"bin\"))\n",
    "    else:\n",
    "        raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import python_vali as vali\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import cvcuda\n",
    "from nvidia import nvimgcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../tests/data/test.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = [\n",
    "    \"__background__\",\n",
    "    \"person\",\n",
    "    \"bicycle\",\n",
    "    \"car\",\n",
    "    \"motorcycle\",\n",
    "    \"airplane\",\n",
    "    \"bus\",\n",
    "    \"train\",\n",
    "    \"truck\",\n",
    "    \"boat\",\n",
    "    \"traffic light\",\n",
    "    \"fire hydrant\",\n",
    "    \"N/A\",\n",
    "    \"stop sign\",\n",
    "    \"parking meter\",\n",
    "    \"bench\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"sheep\",\n",
    "    \"cow\",\n",
    "    \"elephant\",\n",
    "    \"bear\",\n",
    "    \"zebra\",\n",
    "    \"giraffe\",\n",
    "    \"N/A\",\n",
    "    \"backpack\",\n",
    "    \"umbrella\",\n",
    "    \"N/A\",\n",
    "    \"N/A\",\n",
    "    \"handbag\",\n",
    "    \"tie\",\n",
    "    \"suitcase\",\n",
    "    \"frisbee\",\n",
    "    \"skis\",\n",
    "    \"snowboard\",\n",
    "    \"sports ball\",\n",
    "    \"kite\",\n",
    "    \"baseball bat\",\n",
    "    \"baseball glove\",\n",
    "    \"skateboard\",\n",
    "    \"surfboard\",\n",
    "    \"tennis racket\",\n",
    "    \"bottle\",\n",
    "    \"N/A\",\n",
    "    \"wine glass\",\n",
    "    \"cup\",\n",
    "    \"fork\",\n",
    "    \"knife\",\n",
    "    \"spoon\",\n",
    "    \"bowl\",\n",
    "    \"banana\",\n",
    "    \"apple\",\n",
    "    \"sandwich\",\n",
    "    \"orange\",\n",
    "    \"broccoli\",\n",
    "    \"carrot\",\n",
    "    \"hot dog\",\n",
    "    \"pizza\",\n",
    "    \"donut\",\n",
    "    \"cake\",\n",
    "    \"chair\",\n",
    "    \"couch\",\n",
    "    \"potted plant\",\n",
    "    \"bed\",\n",
    "    \"N/A\",\n",
    "    \"dining table\",\n",
    "    \"N/A\",\n",
    "    \"N/A\",\n",
    "    \"toilet\",\n",
    "    \"N/A\",\n",
    "    \"tv\",\n",
    "    \"laptop\",\n",
    "    \"mouse\",\n",
    "    \"remote\",\n",
    "    \"keyboard\",\n",
    "    \"cell phone\",\n",
    "    \"microwave\",\n",
    "    \"oven\",\n",
    "    \"toaster\",\n",
    "    \"sink\",\n",
    "    \"refrigerator\",\n",
    "    \"N/A\",\n",
    "    \"book\",\n",
    "    \"clock\",\n",
    "    \"vase\",\n",
    "    \"scissors\",\n",
    "    \"teddy bear\",\n",
    "    \"hair drier\",\n",
    "    \"toothbrush\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "model = torchvision.models.detection.ssd300_vgg16(\n",
    "    weights=torchvision.models.detection.SSD300_VGG16_Weights.COCO_V1)\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-accelerated decoder\n",
    "pyDec = vali.PyDecoder(\n",
    "    url,\n",
    "    {},\n",
    "    gpu_id=0)\n",
    "\n",
    "# GPU-accelerated converters\n",
    "pyCvt = [\n",
    "    vali.PySurfaceConverter(\n",
    "        pyDec.Format,\n",
    "        vali.PixelFormat.RGB,\n",
    "        gpu_id=0),\n",
    "\n",
    "    vali.PySurfaceConverter(\n",
    "        vali.PixelFormat.RGB,\n",
    "        vali.PixelFormat.RGB_PLANAR,\n",
    "        gpu_id=0)\n",
    "]\n",
    "\n",
    "# nvimagecodec JPEG encoder is used instead of vali.PyNvJpegEncoder.\n",
    "# It's done just for illustration purposes, to show the CAI memory sharing.\n",
    "encoder = nvimgcodec.Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate Surfaces\n",
    "surfaces = [\n",
    "    vali.Surface.Make(\n",
    "        format=pyDec.Format,\n",
    "        width=pyDec.Width,\n",
    "        height=pyDec.Height,\n",
    "        gpu_id=0),\n",
    "\n",
    "    vali.Surface.Make(\n",
    "        format=vali.PixelFormat.RGB,\n",
    "        width=pyDec.Width,\n",
    "        height=pyDec.Height,\n",
    "        gpu_id=0),\n",
    "\n",
    "    vali.Surface.Make(\n",
    "        format=vali.PixelFormat.RGB_PLANAR,\n",
    "        width=pyDec.Width,\n",
    "        height=pyDec.Height,\n",
    "        gpu_id=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_to_tensor(seek_frame: int) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    This function decodes single video frame and exports it\n",
    "    to torch cuda tensor.\n",
    "\n",
    "    Args:\n",
    "        seek_frame(int): number of frame to decode\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: Planar RGB CUDA float tensor normalized to\n",
    "        model liking.\n",
    "    \"\"\"\n",
    "    # Decode single Surface\n",
    "    seek_ctx = vali.SeekContext(seek_frame)\n",
    "    success, details = pyDec.DecodeSingleSurface(surfaces[0], seek_ctx)\n",
    "    if not success:\n",
    "        print(details)\n",
    "        raise StopExecution\n",
    "\n",
    "    # Go through color conversion chain\n",
    "    for i in range(0, len(pyCvt)):\n",
    "        success, details = pyCvt[i].Run(surfaces[i], surfaces[i+1])\n",
    "        if not success:\n",
    "            print(details)\n",
    "            raise StopExecution\n",
    "\n",
    "    img_tensor = torch.from_dlpack(surfaces[2])\n",
    "    img_tensor = img_tensor.clone().detach()\n",
    "    img_tensor = img_tensor.type(dtype=torch.cuda.FloatTensor)\n",
    "\n",
    "    # Normalize tensor to meet the NN expectations.\n",
    "    img_tensor = torch.divide(img_tensor, 255.0)\n",
    "    data_transforms = torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "\n",
    "    return data_transforms(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(surface_tensor: torch.tensor) -> tuple[list[list[np.int32]], list[str]]:\n",
    "    \"\"\"\n",
    "    Runs inference on input tensor.\n",
    "\n",
    "    Args:\n",
    "        surface_tensor(torch.tensor): input tensor\n",
    "\n",
    "    Returns:\n",
    "        list[list[np.int32]]: List of detection bboxes\n",
    "        list[str]: Labels\n",
    "    \"\"\"\n",
    "    input_batch = surface_tensor.unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    # Run inference.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_batch)\n",
    "\n",
    "    # Collect segmentation results.\n",
    "    pred_scores = outputs[0][\"scores\"].detach().cpu().numpy()\n",
    "    pred_bboxes = outputs[0][\"boxes\"].detach().cpu().numpy()\n",
    "\n",
    "    confidence = 0.74\n",
    "\n",
    "    labels = [coco_names[i] for i in outputs[0][\"labels\"].cpu().numpy()]\n",
    "    bboxes = pred_bboxes[pred_scores >= confidence].astype(np.int32)\n",
    "\n",
    "    return bboxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(surface_rgb: vali.Surface, bboxes: list[list[np.int32]],\n",
    "                labels: list[str]) -> nvimgcodec.nvimgcodec_impl.Image:\n",
    "    \"\"\"\n",
    "    Runs inference on input tensor.\n",
    "\n",
    "    Args:\n",
    "        surface_rgb(vali.Surface): interleaved RGB Surface which corresponds\n",
    "        to tensor\n",
    "        bboxes(list[list[np.int32]]): detection bboxes\n",
    "        labels(list[str]): detection labels\n",
    "\n",
    "    Returns:\n",
    "        nvimgcodec.nvimgcodec_impl.Image: nvcv image with bboxes drawn\n",
    "    \"\"\"\n",
    "\n",
    "    # Create tensor from RGB Surface for OSD operations.\n",
    "    nvcv_tensor = cvcuda.as_tensor(surface_rgb, \"HWC\")\n",
    "\n",
    "    if len(bboxes) > len(labels):\n",
    "        print(\"Some detections don't have labels\")\n",
    "        raise StopExecution\n",
    "\n",
    "    # Draw bounding boxes and labels.\n",
    "    bbox_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(0, len(bboxes)):\n",
    "        bbox_list.append(\n",
    "            cvcuda.BndBoxI(\n",
    "                box=tuple(bboxes[i]),\n",
    "                thickness=5,\n",
    "                borderColor=(0, 255, 0, 255),\n",
    "                fillColor=(0, 0, 255, 0)))\n",
    "\n",
    "        label_list.append(\n",
    "            cvcuda.Label(\n",
    "                utf8Text=labels[i],\n",
    "                fontSize=12,\n",
    "                tlPos=(bboxes[i][0], bboxes[i][1]),\n",
    "                fontColor=(0, 255, 0, 255),\n",
    "                bgColor=(0, 0, 255, 0)))\n",
    "\n",
    "    batch_bounding_boxes = cvcuda.Elements(elements=[bbox_list])\n",
    "    batch_labels = cvcuda.Elements(elements=[label_list])\n",
    "\n",
    "    cvcuda.osd_into(nvcv_tensor, nvcv_tensor, batch_bounding_boxes)\n",
    "    cvcuda.osd_into(nvcv_tensor, nvcv_tensor, batch_labels)\n",
    "\n",
    "    # Both nvcv image and tensor are sharing actual vRAM memory with\n",
    "    # RGB Surface. Hence we can draw bboxes over tensor but return image.\n",
    "    return nvimgcodec.as_image(surface_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference doesn't facilitate batching for simplicity. \\\n",
    "Hence detection results may not be the best. \\\n",
    "Please take that into account and don't scold sloppy bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(seek_frame=widgets.IntSlider(\n",
    "    min=0, max=pyDec.NumFrames - 1, step=1, value=0))\n",
    "def show(seek_frame: int) -> None:\n",
    "    video_frame = decode_to_tensor(seek_frame)\n",
    "    detections, labels = run_inference(video_frame)\n",
    "    rgb_frame = draw_bboxes(surfaces[1], detections, labels)\n",
    "    print(rgb_frame)\n",
    "\n",
    "    encoder.write(\"frame.jpg\", rgb_frame)\n",
    "    display(Image.open(\"frame.jpg\"), display_id=\"decoded_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"frame.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
